### **文档：低光照图像去噪任务的定量评估指标详解**

本文件旨在详细阐述在低光照图像去噪项目中，用于定量评估模型性能的各项核心指标。这些指标分为两大类：**图像质量评估指标**和**模型效率评估指标**。

#### **第一部分：图像质量评估指标**

此类指标用于衡量模型输出的去噪图像与“标准答案”（Ground Truth）之间的保真度与感知相似度。

---

##### **1. PSNR (Peak Signal-to-Noise Ratio, 峰值信噪比)**

* **核心思想**:
    PSNR是图像处理领域最传统、最广泛使用的保真度度量指标。它建立在**均方误差（Mean Squared Error, MSE）**的基础之上，通过计算对应像素点之间的误差来衡量图像的失真程度。其核心假设是：像素误差越小，图像质量越高。

* **计算方式**:
    1.  首先，计算去噪图像 `Ŷ` 与真实图像 `Y` 之间的均方误差MSE：
        $$
        MSE = \frac{1}{H \times W \times C} \sum_{i=1}^{H} \sum_{j=1}^{W} \sum_{k=1}^{C} (Y_{(i,j,k)} - \hat{Y}_{(i,j,k)})^2
        $$
        其中 `H, W, C` 分别是图像的高、宽和通道数。
    2.  然后，根据MSE计算PSNR值：
        $$
        PSNR = 10 \cdot \log_{10}\left(\frac{MAX_I^2}{MSE}\right)
        $$
        其中，$MAX_I$ 是图像像素值的最大可能值。对于8位图像，它是255；对于归一化到 `[0, 1]` 的浮点图像，它是1.0。

* **指标解读**:
    * PSNR的单位是分贝（dB）。
    * **数值越高越好**，表示去噪图像与真实图像的像素级差异越小，失真度越低。
    * **局限性**: PSNR只关注像素值的绝对差异，有时其结果与人眼的主观感知质量并不完全一致。例如，一张轻微模糊但无噪点的图像，其PSNR可能低于一张锐利但有少量伪影的图像。

* **实现要点 (用于后续生成代码)**:
    * 输入：两张尺寸和数据类型完全相同的图像（通常为PyTorch Tensor或NumPy Array）。
    * 数据范围（Data Range）必须明确指定（例如255或1.0）。
    * 可使用`torchmetrics`、`skimage.metrics.peak_signal_noise_ratio`等库函数直接计算。

---

##### **2. SSIM (Structural Similarity Index Measure, 结构相似性)**

* **核心思想**:
    SSIM的设计初衷是为了弥补PSNR不关心图像结构的缺陷。它认为人眼视觉系统主要关注场景中的结构信息。因此，SSIM从**亮度（Luminance）**、**对比度（Contrast）**和**结构（Structure）**三个维度来综合评估两张图像的相似性。

* **计算方式**:
    SSIM在图像上使用一个滑动窗口进行计算，对每个窗口内的图像块计算三项指标，然后综合得出最终得分。
    1.  **亮度比较**: 基于图像块的平均灰度值。
    2.  **对比度比较**: 基于图像块的灰度标准差。
    3.  **结构比较**: 基于图像块的灰度协方差。
    最终的SSIM值是这三个分量的加权乘积。

* **指标解读**:
    * SSIM的取值范围为 `[-1, 1]`。
    * **数值越接近1越好**，表示两张图像在结构上越相似。值为1代表两张图像完全相同。
    * 相比PSNR，SSIM通常能更好地反映人眼对图像质量的主观判断。

* **实现要点**:
    * 输入：两张尺寸相同的图像。
    * 需要指定数据范围（Data Range）。
    * 滑动窗口大小（`win_size`）是一个可调参数，通常为奇数，如7或11。
    * 可使用`torchmetrics`、`skimage.metrics.structural_similarity`等库函数。

---

##### **3. LPIPS (Learned Perceptual Image Patch Similarity, 学习感知图像块相似度)**

* **核心思想**:
    LPIPS是近年来被广泛采用的、更先进的感知度量指标。它不再依赖于手工设计的公式，而是利用一个**预训练的深度神经网络**（如AlexNet, VGG）来模仿人类的视觉感知系统。其核心思想是：如果两张图像在人眼看来是相似的，那么它们在深度网络的不同层级上提取出的**深层特征**也应该是相似的。

* **计算方式**:
    1.  将去噪图像 `Ŷ` 和真实图像 `Y` 分别输入到一个固定的、预训练好的深度网络中。
    2.  从网络的多个卷积层中提取出各自的特征图（Feature Maps）。
    3.  对每个层级的特征图进行归一化处理。
    4.  计算`Ŷ`和`Y`在对应层级上特征图之间的L2距离（欧氏距离）。
    5.  将所有层级的距离进行加权求和，得到最终的LPIPS分数。

* **指标解读**:
    * **数值越低越好**，表示两张图像在感知上越相似。
    * LPIPS对于模糊、纹理失真、伪影等问题非常敏感，能极好地衡量生成图像的**真实感**和**细节还原能力**，这与你项目中“细节保留”的目标高度契合。

* **实现要点**:
    * 需要安装专门的`lpips`库。
    * 输入图像（PyTorch Tensor）需要被归一化到 `[-1, 1]` 的范围内。
    * 输入张量的形状通常为 `(N, C, H, W)`。
    * 需要指定使用的网络骨干（如`'alex'`或`'vgg'`）。

#### **第二部分：模型效率评估指标**

此类指标用于衡量模型本身的计算成本和存储需求，是评估模型实用性的关键。

---

##### **4. 参数量 (Parameters)**

* **核心思想**:
    指模型中所有**可训练参数**（权重和偏置）的总数量。它直接决定了模型文件的大小和对存储空间的需求。

* **计算方式**:
    遍历模型的所有层，累加每一层可训练参数张量中的元素数量。

* **指标解读**:
    * 单位通常是“百万”（M）。
    * **数值越低越好**（在性能相近的前提下），代表模型更轻量，更易于部署。

* **实现要点**:
    * 在PyTorch中，可以通过 `sum(p.numel() for p in model.parameters() if p.requires_grad)` 来计算。

---

##### **5. FLOPs (Floating Point Operations, 浮点运算次数)**

* **核心思想**:
    指模型完成一次**前向传播**所需要的浮点运算（通常是乘法和加法）的总次数。它衡量的是模型的**计算复杂度**，与模型的推理速度高度相关。

* **计算方式**:
    这个指标无法手动简单计算，需要借助专门的库（如`fvcore`, `thop`）来分析模型的计算图。这些库会“钩住”模型中的每个操作（如卷积、全连接），并根据其输入输出尺寸累加其对应的FLOPs。

* **指标解读**:
    * 单位通常是“GFLOPs”（$10^9$次浮点运算）。
    * **数值越低越好**，代表模型计算效率更高。
    * 注意：FLOPs是**与输入图像尺寸相关**的，在报告时必须注明测试所用的图像分辨率。

* **实现要点**:
    * 需要提供一个与实际推理时尺寸相同的**样本输入张量（dummy input）**，以便库函数追踪计算图。

---

##### **6. 单图平均推理时间 (Average Inference Time)**

* **核心思想**:
    直接测量模型在**特定硬件**（如某型号的GPU）上处理单张图像所需的时间。这是衡量模型**实际运行速度**的最直观指标。

* **计算方式**:
    1.  将模型设置为评估模式 (`model.eval()`)。
    2.  在`torch.no_grad()`环境下运行。
    3.  进行若干次“热身”（warm-up）推理，以稳定GPU时钟频率。
    4.  循环处理一批测试图像，使用`torch.cuda.Event`或`time.time()`并配合`torch.cuda.synchronize()`来精确计时。
    5.  计算总时间除以图像数量，得到平均时间。

* **指标解读**:
    * 单位通常是“毫秒/图”（ms/image）。
    * **数值越低越好**。
    * **必须注明测试硬件**（如NVIDIA RTX 4090），因为该指标高度依赖于硬件平台。

* **实现要点**:
    * 必须在GPU上进行计时，并使用`torch.cuda.synchronize()`来确保CPU和GPU操作同步，避免异步执行带来的计时误差。
    * 关闭梯度计算是必须的。

## 评价体系的适当补充

### 先看你代码里新增/可复用的“钩子”

- **ΔE_{2000}（Lab 色差）**：`DeltaE00Loss`，输入 sRGB[0,1]，Kornia 转 Lab 后计算，与你项目“抑制串扰导致的色偏”高度贴合。
- **SSIM（sRGB 域）**：基于 Kornia 的 `SSIMLoss`，可直接当评测函数复用。
- **物理一致性项（RAW 域）**：`PhysicsConsistencyLoss` 实现了 `|| K * B̂_raw - Align(A_raw) ||` 的 L1 约束；这是验证“预补偿 + 固定 PSF”的最直接度量。
- **物理一致性项（sRGB 域）**：`PhysicalConsistencyLossSRGB` + `CrosstalkPSF`（固定核，仅用于损失/评测分支）可在 sRGB 上做同样的一致性检验。
- **损失组合器**：`HybridLossPlus` 已把上面几类项做了可插拔组合，也内置了不确定性加权（训练期用，评测期不用）。
- **网络结构策略**：`create_newbp_net` 采用 **Scenario B**（**前向不再卷 K**，只在损失/评测支路使用固定 PSF），避免“双重串扰”。这为“以评测来证明补偿有效”创造了干净前提。

------

### 精简必选：五个指标就够（各司其职）

> 目标：最小集合，最大辨识度。每个指标都服务于“物理消串扰 + 细节不抹平 + 色彩变干净”。

1. **Linear-PSNR / Linear-SSIM（线性域）**
   - **必要性**：物理还原应在**线性域**检验，避免 sRGB γ 非线性“掩盖真实增益”。
   - **作用**：量化**信号保真**的底线；NewBP 如能在相同噪声水平下提高线性域 PSNR/SSIM，说明补偿不是“以涂抹换稳态”。
   - **实现**：复用你评测脚本的 PSNR/SSIM 实现；只需确保输入是线性标定、同裁剪口径。
2. **LPIPS@ sRGB（或保留你已有的 PerceptualLoss 只做训练）**
   - **必要性**：给出**感知质量**的一维锚点；更贴近主观观感。
   - **作用**：防止“线性域指标涨了，视觉却更糟”的反向激励。
   - **实现**：你在 `HybridLossPlus` 中已做了可选 LPIPS 加载；评测期直接 `.eval()` 前向求均值即可（未安装可跳过）。
3. **ΔE_{2000}（均值 + P95）**
   - **必要性**：直击“串扰导致的**色污染/色偏**”；单纯的 PSNR/SSIM 很难揭露色彩的系统性误差。
   - **作用**：你希望“颜色更干净”，ΔE 能把**整体色差**与**极端区域（P95）**的改善量化出来。
   - **实现**：直接复用 `DeltaE00Loss` 的前向作为评测函数（注意只在评测里求值，不反传）。
4. **Phys-Cons（物理一致性误差，RAW 与/或 sRGB）**
   - **必要性**：这是**你方法的杀手锏指标**，能直接回答“B̂ 经过已知 PSF 后，是否**回到**短曝 A 的观测域”。
   - **作用**：证明“**预补偿有效**”——如果该误差显著下降，恰是你论文叙事的核心证据。
   - **实现**：评测阶段用 `PhysicsConsistencyLoss`（RAW）与/或 `PhysicalConsistencyLossSRGB`（sRGB）计算 **MAE**；日志里加单位“/1.0”。
5. **RGB-PSNR（三通道分别汇报）**
   - **必要性**：不同波段串扰强度不同；分通道能定位“哪一通道污染被压下去了”。
   - **作用**：与 ΔE 互证，展示**R/G/B 定向收益**（例如边缘红晕被抑制）。
   - **实现**：在评测循环里分别对 `R/G/B` 计算 PSNR；输出“R-PSNR/G-PSNR/B-PSNR”。

> **可选的小加分（不必进主表）**：**Edge-ΔE**（仅在边缘掩膜上统计 ΔE_{2000} 的均值/P95）。它特别敏感于“边缘串扰色晕”，但实现只需用 Sobel/梯度阈值取掩膜再统计即可，成本很低。

------

### 为什么这五项对你的项目“刚好够用”

- **物理一致性（Phys-Cons）** = 你的方法论之锚
   你在 `newbp_net_arch.py` 明确采用“前向不卷 K、只在损失支路施加固定 PSF”的 **Scenario B** 设定，天然对应“输出端一致性”的验证口径。把 `CrosstalkPSF` 当评测算子计算 `||PSF(B̂) - Align(A)||`，能一锤定音地说明：**我们不是把颜色抹平了，而是学到了一张能“穿过物理退化就复原”的预补偿图**。
- **ΔE_{2000} + RGB-PSNR** = 串扰抑制的可视化证据
   串扰是**跨通道耦合**的系统误差。ΔE_{2000} 是人眼色差的标准量化；RGB-PSNR 把改善“落在了哪个通道”讲清楚。你的 `DeltaE00Loss` 现成可用，易复现实验。
- **Linear-PSNR/SSIM + LPIPS（sRGB）** = 保真与观感的双安全阀
   线性域指标守住**成像物理正确性**，LPIPS 守住**视觉观感**。这两条线避免“只赢一边”的偏执优化。

------

### 精简之外，不建议现在就上的指标（原因）

- **GMSD、VIF/IFC、DISTS、MS-SSIM**：都值得做“论文附录/消融”，但对你主叙事**边际信息重复**；引入新依赖与计算成本，不如把“Edge-ΔE”这样**定向敏感的小指标**加进来更具性价比。
- **NIQE/BRISQUE/TOPIQ/ARNIQA（无参考）**：用于**无 GT 场景**很有用；若你当前主要在有 GT 的 SID/合成压力集上做验证，可以先不进主表，避免“无参考指标”把读者带偏。

------

### 最后：如何把它们“无痛接”进你现有评测脚本

- **ΔE_{2000}**：用你现成的 `DeltaE00Loss`，评测时前向得到 `mean`，另加 `P95`（对每图像像素 ΔE 展平取分位数）。
- **Phys-Cons**：复用 `PhysicsConsistencyLoss`（RAW）与/或 `PhysicalConsistencyLossSRGB`（sRGB），评测期禁用梯度，仅记录 `MAE`；与训练时同一个 `PSF` 与 `expo_ratio`。
- **Linear-PSNR/SSIM**：确保在**线性域**、同一裁剪口径下计算；与 sRGB 面板分栏展示，避免口径混淆。
- **LPIPS**：如环境已装 `lpips`，直接 `model.eval(); val = model(x,y).mean()`；未安装则在配置里自动降级为“跳过并记录 NaN”。
- **RGB-PSNR**：简单循环 `for c in 0..2` 分通道计算并记录。

> 日志建议：每个指标都记录 `mean ± std`，并给出**配对提升**（相对 baseline NAFNet）的 `Δmean` 与 95% CI。表格主行只放上述“五项 + Edge-ΔE（可选）”，其余作为附录或补充图。

------

### 小结（可直接抄作“评测面板”）

- **线性域**：PSNR，SSIM
- **sRGB感知**：LPIPS
- **色彩**：ΔE_{2000}（mean，P95），RGB-PSNR
- **物理一致性**：Phys-Cons（RAW 与/或 sRGB，MAE）
- **可选一行**：Edge-ΔE（mean，P95）

这一套**五项 + 可选一项**，与您当前代码天然对齐、复现成本低，却能把**“物理预补偿抑制串扰、细节不涂抹、色彩更干净”**三个卖点清晰量化出来。等你把评测脚本/runner 传上来，我会把这些指标“即插即用”接进去，并把日志/表格输出规范化。
